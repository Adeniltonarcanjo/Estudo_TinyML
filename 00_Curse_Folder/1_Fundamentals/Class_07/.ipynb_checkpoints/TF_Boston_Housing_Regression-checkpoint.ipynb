{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo2JiEtkzvQL"
   },
   "source": [
    "# House Pricing Regression using Dense Neural Network (DNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z56YN3JZ0Duh"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YfPnR74Gzc_q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrGLDV6q0PCc"
   },
   "source": [
    "## Upload and Explore Dataset\n",
    "[The Boston house-price data](http://lib.stat.cmu.edu/datasets/boston) \n",
    "* This is a dataset taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
    "* There are 506 samples, each one with 13 attributes (Features `Xi` from 0 to 12) of houses at different locations around the Boston suburbs in the late 1970s. The attributes themselves are defined in the StatLib website (as per capta crime rate in the area, number of rooms, distance  from employemment center, etc).\n",
    "- Target (`Y`) is the median values of the houses at a location (in USD 1,000).\n",
    "\n",
    "**Goal**\n",
    "*  Our goal is to build a regression model that takes these **13 features as input** and **output a single value prediction** of the \"median value of owner-occupied homes (in USD 1000).\"\n",
    "* Dataset can be download direct from: [tf.keras.datasets.boston_housing](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ib2Ihepx0N6h"
   },
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pq1bMIRd38b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qHaUYnSs4bq4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44ENgGg2Qudp"
   },
   "source": [
    "### Exploring Target (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "imESCCOODh8K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "82O77YHNybhA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min price in $K:   5.0\n",
      "Max price in $K:   22.4\n",
      "Mean price in $K:  50.0\n"
     ]
    }
   ],
   "source": [
    "print('Min price in $K:  ',y_train.min())\n",
    "print('Max price in $K:  ',round(y_train.mean(),2))\n",
    "print('Mean price in $K: ',y_train.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1SCj8H9rysOM"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histograma\n",
    "plt.hist(y_train, label='train')\n",
    "plt.hist(y_test, label = 'test')\n",
    "plt.xlabel('Price in K$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qyfWBrrW9gAd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TMu0y_Az4hRr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
       "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
       "        18.72   ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_M47lzg7z3vI"
   },
   "source": [
    "### Exploring Input Features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sgy3E-Y7D__F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0 ==> range from 0.00632 to 88.9762\n",
      "Feature 1 ==> range from 0.0 to 100.0\n",
      "Feature 2 ==> range from 0.46 to 27.74\n",
      "Feature 3 ==> range from 0.0 to 1.0\n",
      "Feature 4 ==> range from 0.385 to 0.871\n",
      "Feature 5 ==> range from 3.561 to 8.725\n",
      "Feature 6 ==> range from 2.9 to 100.0\n",
      "Feature 7 ==> range from 1.1296 to 10.7103\n",
      "Feature 8 ==> range from 1.0 to 24.0\n",
      "Feature 9 ==> range from 188.0 to 711.0\n",
      "Feature 10 ==> range from 12.6 to 22.0\n",
      "Feature 11 ==> range from 0.32 to 396.9\n",
      "Feature 12 ==> range from 1.73 to 37.97\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_train[0])):\n",
    "  print(\"Feature {} ==> range from {} to {}\".format(\n",
    "      i, x_train[:,i].min(), x_train[:,i].max()\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hXAskOWeGHSx"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature = 1\n",
    "plt.hist(x_train[:,feature], label='train')\n",
    "plt.hist(x_test[:,feature], label = 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "btqWSp9dSrCB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print (x_train.max())\n",
    "print (x_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-H0LwB_7von"
   },
   "source": [
    "### Preprocessing Data \n",
    "\n",
    "**Normalizing Data**: \n",
    "We notice that values range varies depending on the type of the feature. If we are training a neural network, for various reasons it's easier if we treat all values as between 0 and 1 (or at least with similar ranges), a process called 'normalizing'. In this case, all features will be `rescaled`.\n",
    "\n",
    "The standard score of a sample `x` is calculated as:\n",
    "\n",
    "        z = (x - u) / s\n",
    "\n",
    "where `u` is the mean of the training samples or zero if `with_mean=False` and `s` is the standard deviation of the training samples or one if `with_std=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uZrGVMsH0X3F"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# first we fit the scaler on the training dataset\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# then we call the transform method to scale both the training and testing data\n",
    "x_train_norm = scaler.transform(x_train)\n",
    "x_test_norm = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MG_fd0Ig5BuM"
   },
   "source": [
    "Another way do normalize data directly with numpy is:\n",
    "- Get per-feature statistics (mean, standard deviation) from the training set to normalize by:\n",
    "  - x_train_mean = np.mean(x_train, axis=0)\n",
    "  - x_train_std = np.std(x_train, axis=0)\n",
    "  - x_train_norm = (x_train - x_train_mean) / x_train_std\n",
    "\n",
    "  - x_test_norm = (x_test - x_train_mean) / x_train_std\n",
    "\n",
    "**Note** that the quantities used for normalizing the test data are computed using the training data. You should never use in your workflow any quantity computed on the test data, even for something as simple as data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "mMP87jskSZuv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.234847178400438\n",
      "-3.8172503201932715\n"
     ]
    }
   ],
   "source": [
    "print (x_train_norm.max())\n",
    "print (x_train_norm.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amLdhSLI6gzT"
   },
   "source": [
    "A sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bDL5Es5W6caw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n",
      "  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n",
      "  0.8252202 ]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_norm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYMsyOk8-xnf"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JBUukyQ0INrf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ezpCJySN5h2Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "sDlDs9YO5qk_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZimwlA92lLr"
   },
   "source": [
    "The model can be created thi, for example with this layers:\n",
    "- [input] ==> [hidden] ==> [output]:\n",
    "  - 13 ==> [20] ==>  1\n",
    "\n",
    "The **Input Layer** should be 13 (number of features) and the **Output Layer** shoub be 1 to match the target (y). The number of neurons at **Hidden layers** are arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dEdoqWl28dB3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                280       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(input_shape),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNTU33Hn1TRj"
   },
   "source": [
    "Input layer has 13 conections, one for each feature [X]. Each feature goes to each one of the neurons of 1st Dense Layer, that has 20 Neurons. So, total parameters 1st Dense Layer will be ws=(13 x 20) + bs=20 ==> 280. The output layer will be only one Neuron that has one input from the output of previous layer (20 ) + 1 b ==> 21.\n",
    "\n",
    "For simplicity, the input layer can be \"merge with 1st layer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yXHoc5X42iR2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 20)                280       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(20, \n",
    "                          activation='relu', \n",
    "                          input_shape = [13]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfGTI8SY_3AL"
   },
   "source": [
    "##Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzTQem0EHY-O"
   },
   "source": [
    "### Type of errors\n",
    "In statistics, `Mean Absolute Error (MAE)` is a measure of errors between paired observations expressing the same phenomenon. Examples of Y versus X include comparisons of predicted versus observed, subsequent time versus initial time, and one technique of measurement versus an alternative technique of measurement. MAE is calculated as:\n",
    "\n",
    "\n",
    "$$MAE=\\frac{1}{n}\\sum_{i=1}^{n}(\\left|y_{i}-\\hat{y}_{i}\\right|)$$\n",
    "\n",
    "\n",
    "Another alternative to evaluate regression is the `Root Mean Square Error (RMSE)`.\n",
    "This is the root of the  mean of the squared errors. It is a most popular measure of regression model's performance because also keep the same unit as y and larger errors are noted more than with MAE.\n",
    "\n",
    "$$RSME=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}{(y_{i}-\\hat{y}_{i})}^2}$$\n",
    "\n",
    "You can use MSE to calculate loss, but also tracking the MAE or RSME, once those values will have the \"same order\" of the Target (in the case, multiples of USD1,000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7yHe1BU_Cr2"
   },
   "source": [
    "The optimizer used is [ADAM](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam), a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. The hyperparameter \"Learning-Rate\" used is the default ==> 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "NA21O9Y0_BJ7"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae'] # used to monitor the training and testing steps.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJZ4fvT3_yd7"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RxklrX_R_uvn"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train_norm, \n",
    "    y_train,\n",
    "    epochs=1000, \n",
    "    verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xAXSo5-HCIo"
   },
   "source": [
    "Inspecting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PXzMCGzVUuTx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 5.5858 - mae: 1.6754\n",
      "Training data MSE: 1.7\n"
     ]
    }
   ],
   "source": [
    "train_eval = model.evaluate(x_train_norm, y_train)\n",
    "print (\"Training data MSE: {:.2}\".format(train_eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ShUfx2ZSCylX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "npIubpXaKl6u"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='MSE')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "#plt.ylim([0,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "g6qHpwg8BpZi"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'], label='MAE')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss in $K')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "#plt.ylim([0,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYHTdEJVH0tZ"
   },
   "source": [
    "## Testing the trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QBuJGqbSH6xT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 15.7593 - mae: 2.5785\n",
      "Test data MAE: 2.6\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(x_test_norm, y_test)\n",
    "print (\"Test data MAE: {:.2}\".format(test_eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "J4H-5TF42ZjL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.97"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsme = round(np.sqrt(test_eval[0]), 3)\n",
    "rsme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "we1LXnkDzbaS"
   },
   "source": [
    "The model has an RSME error of around USD4,000 and an MAE of around USD 2,600, what is very good for house's price estimation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_-PyEde1sAq"
   },
   "source": [
    "Note: With features **not normalized**, we got loss (MSE): 22.0815; RSME: USD4,700 and  MAE: USD3,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "tkaTLMaTIbIL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "[[ 8.392538]\n",
      " [18.77521 ]\n",
      " [21.924768]\n",
      " [32.581852]\n",
      " [24.503143]]\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(x_test_norm)\n",
    "print(y_hat[:5]) # get the output predict values for the 5 first samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "9p9buLk54A1W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.2, 18.8, 19. , 27. , 22.2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5] # get the output real known values for the 5 first samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ERuEyCmx4QHY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat, label='predictions', color = 'b')\n",
    "plt.hist(y_test, label = 'real values', color = 'r', alpha=0.5)\n",
    "plt.xlabel('Price in K$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQgmjypmxaFP"
   },
   "source": [
    "## Doing Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "EIior9FBvdcs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = np.array([1.1, 0., 9., 0., 0.6, 7., 92., 3.8 , 4., 300., 21., 200, 19.5])\n",
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Vp2mV37ZyOXE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "2qp7KDtgyz8g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = np.reshape(xt, (1, 13))\n",
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1pLLiifrzO-3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   0. ,   9. ,   0. ,   0.6,   7. ,  92. ,   3.8,   4. ,\n",
       "        300. ,  21. , 200. ,  19.5]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "XDlArmS2xfuR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28659955, -0.48361547, -0.30934443, -0.25683275,  0.36401915,\n",
       "         1.03386853,  0.82381223,  0.02945662, -0.62624905, -0.63729594,\n",
       "         1.14850044, -1.64672402,  0.93287232]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_norm = scaler.transform(xt)\n",
    "xt_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "fHbXuOGkzJ-n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15.490016]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = model.predict(xt_norm)\n",
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lfb5RGKT0rs3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "xt = np.array([1.1, 0., 9., 0., 0.6, 7., 92., 3.8 , 4., 300., 21., 200, 19.5])\n",
    "xt = np.reshape(xt, (1, 13))\n",
    "xt_norm = scaler.transform(xt)\n",
    "yt = model.predict(xt_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUNbBC_FgcWZ"
   },
   "source": [
    "## Finding the correct Hyperparameters\n",
    "- [KerasTuner](https://keras.io/keras_tuner/)\n",
    "\n",
    "KerasTuner is an easy-to-use, scalable hyperparameter optimization framework that solves the pain points of hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "dql5K0r9gU1F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from keras-tuner) (8.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from keras-tuner) (1.23.3)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from keras-tuner) (2.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from keras-tuner) (2.27.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.1.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (3.0.20)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (2.11.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (61.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.18.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.4.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.9)\n",
      "Requirement already satisfied: asttokens in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (2.0.5)\n",
      "Requirement already satisfied: executing in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from stack-data->ipython->keras-tuner) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython->keras-tuner) (1.16.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (3.19.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.37.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.33.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\adeniton\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.1.3 kt-legacy-1.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "AP1tw9u9g5Uf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "VLYVscNQkaWS"
   },
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.boston_housing\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "pE7gSlcTkl20"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# first we fit the scaler on the training dataset\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# then we call the transform method to scale both the training and testing data\n",
    "x_train_norm = scaler.transform(x_train)\n",
    "x_test_norm = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UHfySq-hJHo"
   },
   "source": [
    "Write a function that creates and returns a Keras model. Use the `hp` argument to define the hyperparameters during model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "qbvjlmNdhBn6"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      hp.Choice('units', [10, 20, 30]),\n",
    "      activation='relu'))\n",
    "  \n",
    "  model.add(tf.keras.layers.Dense(1))\n",
    "  model.compile(optimizer='adam', loss='mse')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsNpzZpeh2Hi"
   },
   "source": [
    "Initialize a tuner (here, RandomSearch). We use objective to specify the objective to select the best models, and we use max_trials to specify the number of different models to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "zufG9sUjh1xV"
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN6Ci84OiFaZ"
   },
   "source": [
    "Start the search and get the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "WnkdoSzLiJUY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 01m 37s]\n",
      "val_loss: 17.443344116210938\n",
      "\n",
      "Best val_loss So Far: 15.598858833312988\n",
      "Total elapsed time: 00h 03m 05s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "20                |30                |units\n",
      "\n",
      "Epoch 1/500\n",
      "13/13 [==============================] - 1s 37ms/step - loss: 575.9824 - val_loss: 595.6401\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 564.0964 - val_loss: 583.3145\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 551.8695 - val_loss: 570.8252\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 539.2969 - val_loss: 557.6577\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 526.0415 - val_loss: 543.9119\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 512.1573 - val_loss: 529.1893\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 497.5724 - val_loss: 513.6486\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 481.7740 - val_loss: 497.4769\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 465.3874 - val_loss: 480.5831\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 448.8433 - val_loss: 462.5096\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 430.6781 - val_loss: 444.7567\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 413.0287 - val_loss: 426.0660\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 394.7038 - val_loss: 407.2217\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 376.4040 - val_loss: 388.1831\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 357.8591 - val_loss: 369.0997\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 339.6694 - val_loss: 349.9046\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 321.2990 - val_loss: 331.2419\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 303.6698 - val_loss: 312.8360\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 286.0227 - val_loss: 295.2285\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 269.1414 - val_loss: 278.0179\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 252.9176 - val_loss: 261.0335\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 236.8645 - val_loss: 245.1699\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 221.6810 - val_loss: 230.1870\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 207.4497 - val_loss: 215.4824\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 193.8852 - val_loss: 201.7233\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 181.3800 - val_loss: 188.6369\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 169.0841 - val_loss: 177.0269\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 158.2010 - val_loss: 165.9600\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 147.8456 - val_loss: 155.7475\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 138.4052 - val_loss: 146.1683\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 129.6519 - val_loss: 137.3055\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 121.2631 - val_loss: 129.3351\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 113.7216 - val_loss: 121.7830\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 106.7179 - val_loss: 114.8810\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 100.3416 - val_loss: 108.3873\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 94.3191 - val_loss: 102.4323\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 88.7287 - val_loss: 96.9365\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 83.5494 - val_loss: 91.8431\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 78.6752 - val_loss: 86.9152\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 74.1722 - val_loss: 82.3159\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 69.9159 - val_loss: 78.1663\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 66.0096 - val_loss: 74.1739\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 62.4400 - val_loss: 70.4715\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 59.0163 - val_loss: 67.2433\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 56.0349 - val_loss: 63.9851\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 53.1868 - val_loss: 61.0538\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 50.4687 - val_loss: 58.5830\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 48.1436 - val_loss: 56.0742\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 45.9004 - val_loss: 53.8724\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 43.9851 - val_loss: 51.7296\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 42.0787 - val_loss: 49.7812\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 40.4002 - val_loss: 48.0191\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 38.9383 - val_loss: 46.3462\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 37.5579 - val_loss: 44.8935\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 36.2520 - val_loss: 43.6049\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 35.1725 - val_loss: 42.4009\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 34.1280 - val_loss: 41.2869\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 33.1886 - val_loss: 40.2927\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 32.3282 - val_loss: 39.4117\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 31.5836 - val_loss: 38.5937\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 30.8967 - val_loss: 37.9390\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 30.2302 - val_loss: 37.2487\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 29.6710 - val_loss: 36.5349\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 29.1551 - val_loss: 35.9826\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 28.6604 - val_loss: 35.4441\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 28.2126 - val_loss: 34.9527\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 27.8323 - val_loss: 34.4905\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 27.4534 - val_loss: 34.0250\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 27.1269 - val_loss: 33.6094\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 26.8230 - val_loss: 33.2810\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 26.5112 - val_loss: 32.9245\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 26.2485 - val_loss: 32.6402\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 26.0034 - val_loss: 32.3437\n",
      "Epoch 74/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 25.7660 - val_loss: 32.0522\n",
      "Epoch 75/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 25.5101 - val_loss: 31.7304\n",
      "Epoch 76/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 25.3021 - val_loss: 31.4234\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 27ms/step - loss: 25.0902 - val_loss: 31.1986\n",
      "Epoch 78/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 24.8715 - val_loss: 30.9957\n",
      "Epoch 79/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 24.6897 - val_loss: 30.7671\n",
      "Epoch 80/500\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 24.4982 - val_loss: 30.5383\n",
      "Epoch 81/500\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 24.3066 - val_loss: 30.2921\n",
      "Epoch 82/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 24.1285 - val_loss: 30.1644\n",
      "Epoch 83/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 23.9538 - val_loss: 29.9743\n",
      "Epoch 84/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 23.7818 - val_loss: 29.8174\n",
      "Epoch 85/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 23.6039 - val_loss: 29.6870\n",
      "Epoch 86/500\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 23.4584 - val_loss: 29.5193\n",
      "Epoch 87/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 23.3104 - val_loss: 29.2497\n",
      "Epoch 88/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 23.1387 - val_loss: 29.0450\n",
      "Epoch 89/500\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 22.9849 - val_loss: 28.9161\n",
      "Epoch 90/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 22.8338 - val_loss: 28.7703\n",
      "Epoch 91/500\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 22.6803 - val_loss: 28.6383\n",
      "Epoch 92/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 22.5480 - val_loss: 28.4743\n",
      "Epoch 93/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 22.3927 - val_loss: 28.3647\n",
      "Epoch 94/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 22.2498 - val_loss: 28.2360\n",
      "Epoch 95/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 22.1052 - val_loss: 28.0784\n",
      "Epoch 96/500\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 21.9700 - val_loss: 28.0187\n",
      "Epoch 97/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 21.8339 - val_loss: 27.9806\n",
      "Epoch 98/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 21.7113 - val_loss: 27.7962\n",
      "Epoch 99/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 21.5722 - val_loss: 27.6019\n",
      "Epoch 100/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 21.4424 - val_loss: 27.5776\n",
      "Epoch 101/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 21.3124 - val_loss: 27.4630\n",
      "Epoch 102/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 21.1897 - val_loss: 27.2962\n",
      "Epoch 103/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 21.0599 - val_loss: 27.1780\n",
      "Epoch 104/500\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 20.9435 - val_loss: 27.0238\n",
      "Epoch 105/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 20.8232 - val_loss: 26.9411\n",
      "Epoch 106/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 20.7117 - val_loss: 26.8344\n",
      "Epoch 107/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 20.5850 - val_loss: 26.6855\n",
      "Epoch 108/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 20.4787 - val_loss: 26.6191\n",
      "Epoch 109/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 20.3682 - val_loss: 26.5215\n",
      "Epoch 110/500\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 20.2383 - val_loss: 26.4063\n",
      "Epoch 111/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 20.1234 - val_loss: 26.3003\n",
      "Epoch 112/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 20.0288 - val_loss: 26.2858\n",
      "Epoch 113/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 19.9023 - val_loss: 26.1294\n",
      "Epoch 114/500\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 19.7876 - val_loss: 26.0923\n",
      "Epoch 115/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 19.6671 - val_loss: 25.9304\n",
      "Epoch 116/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 19.5595 - val_loss: 25.8216\n",
      "Epoch 117/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 19.4546 - val_loss: 25.7413\n",
      "Epoch 118/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 19.3343 - val_loss: 25.7172\n",
      "Epoch 119/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 19.2283 - val_loss: 25.6424\n",
      "Epoch 120/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 19.1251 - val_loss: 25.4548\n",
      "Epoch 121/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 19.0294 - val_loss: 25.4771\n",
      "Epoch 122/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 18.9370 - val_loss: 25.2537\n",
      "Epoch 123/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 18.8317 - val_loss: 25.2545\n",
      "Epoch 124/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 18.7170 - val_loss: 25.2071\n",
      "Epoch 125/500\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 18.6036 - val_loss: 25.0849\n",
      "Epoch 126/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 18.5151 - val_loss: 24.9619\n",
      "Epoch 127/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 18.4097 - val_loss: 24.8278\n",
      "Epoch 128/500\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 18.3205 - val_loss: 24.7877\n",
      "Epoch 129/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 18.2150 - val_loss: 24.6479\n",
      "Epoch 130/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 18.1238 - val_loss: 24.5814\n",
      "Epoch 131/500\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 18.0406 - val_loss: 24.4953\n",
      "Epoch 132/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 17.9252 - val_loss: 24.4473\n",
      "Epoch 133/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 17.8488 - val_loss: 24.2781\n",
      "Epoch 134/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 17.7669 - val_loss: 24.3628\n",
      "Epoch 135/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 17.6687 - val_loss: 24.2299\n",
      "Epoch 136/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 17.5906 - val_loss: 24.2407\n",
      "Epoch 137/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 17.4846 - val_loss: 24.1137\n",
      "Epoch 138/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 17.3954 - val_loss: 24.0158\n",
      "Epoch 139/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 17.3061 - val_loss: 23.9598\n",
      "Epoch 140/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 17.2204 - val_loss: 23.8662\n",
      "Epoch 141/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 17.1497 - val_loss: 23.9171\n",
      "Epoch 142/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 17.0460 - val_loss: 23.7544\n",
      "Epoch 143/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 16.9657 - val_loss: 23.7515\n",
      "Epoch 144/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 16.8685 - val_loss: 23.6611\n",
      "Epoch 145/500\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 16.7819 - val_loss: 23.5564\n",
      "Epoch 146/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 16.7285 - val_loss: 23.5933\n",
      "Epoch 147/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 16.6363 - val_loss: 23.3416\n",
      "Epoch 148/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 16.5331 - val_loss: 23.3798\n",
      "Epoch 149/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 16.4530 - val_loss: 23.2238\n",
      "Epoch 150/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 16.3683 - val_loss: 23.1613\n",
      "Epoch 151/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 16.2761 - val_loss: 23.1223\n",
      "Epoch 152/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 16.2060 - val_loss: 23.1121\n",
      "Epoch 153/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 16.1087 - val_loss: 23.0264\n",
      "Epoch 154/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 16.0302 - val_loss: 22.9878\n",
      "Epoch 155/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 15.9614 - val_loss: 23.0271\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 24ms/step - loss: 15.8824 - val_loss: 22.8767\n",
      "Epoch 157/500\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 15.7924 - val_loss: 22.8130\n",
      "Epoch 158/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 15.7101 - val_loss: 22.8338\n",
      "Epoch 159/500\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 15.6335 - val_loss: 22.7205\n",
      "Epoch 160/500\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 15.5621 - val_loss: 22.5985\n",
      "Epoch 161/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 15.4747 - val_loss: 22.6539\n",
      "Epoch 162/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 15.4154 - val_loss: 22.5808\n",
      "Epoch 163/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 15.3104 - val_loss: 22.4115\n",
      "Epoch 164/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 15.2677 - val_loss: 22.3324\n",
      "Epoch 165/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 15.1787 - val_loss: 22.3789\n",
      "Epoch 166/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 15.0977 - val_loss: 22.3086\n",
      "Epoch 167/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 15.0248 - val_loss: 22.2115\n",
      "Epoch 168/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 14.9455 - val_loss: 22.2215\n",
      "Epoch 169/500\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 14.8684 - val_loss: 22.1733\n",
      "Epoch 170/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 14.8033 - val_loss: 22.1778\n",
      "Epoch 171/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 14.7293 - val_loss: 22.0659\n",
      "Epoch 172/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 14.6550 - val_loss: 21.9303\n",
      "Epoch 173/500\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 14.5898 - val_loss: 21.8935\n",
      "Epoch 174/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 14.5157 - val_loss: 21.8335\n",
      "Epoch 175/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 14.4393 - val_loss: 21.9336\n",
      "Epoch 176/500\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 14.3741 - val_loss: 21.8284\n",
      "Epoch 177/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 14.3136 - val_loss: 21.9399\n",
      "Epoch 178/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 14.2240 - val_loss: 21.8018\n",
      "Epoch 179/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 14.1410 - val_loss: 21.7865\n",
      "Epoch 180/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 14.0790 - val_loss: 21.7455\n",
      "Epoch 181/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 14.0012 - val_loss: 21.6188\n",
      "Epoch 182/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 13.9401 - val_loss: 21.5941\n",
      "Epoch 183/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 13.8760 - val_loss: 21.5188\n",
      "Epoch 184/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.7993 - val_loss: 21.5459\n",
      "Epoch 185/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.7366 - val_loss: 21.5884\n",
      "Epoch 186/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.6549 - val_loss: 21.5191\n",
      "Epoch 187/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 13.5944 - val_loss: 21.4590\n",
      "Epoch 188/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 13.5157 - val_loss: 21.3844\n",
      "Epoch 189/500\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 13.4625 - val_loss: 21.2603\n",
      "Epoch 190/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.4054 - val_loss: 21.3977\n",
      "Epoch 191/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 13.3467 - val_loss: 21.4442\n",
      "Epoch 192/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 13.2487 - val_loss: 21.2729\n",
      "Epoch 193/500\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 13.1946 - val_loss: 21.1656\n",
      "Epoch 194/500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 13.1404 - val_loss: 21.1312\n",
      "Epoch 195/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 13.0767 - val_loss: 21.0361\n",
      "Epoch 196/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.0148 - val_loss: 21.1118\n",
      "Epoch 197/500\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 12.9342 - val_loss: 21.0137\n",
      "Epoch 198/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 12.8763 - val_loss: 21.0426\n",
      "Epoch 199/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.8108 - val_loss: 21.0279\n",
      "Epoch 200/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 12.7585 - val_loss: 21.0071\n",
      "Epoch 201/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.6955 - val_loss: 21.0789\n",
      "Epoch 202/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 12.6158 - val_loss: 20.9857\n",
      "Epoch 203/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 12.5679 - val_loss: 20.9817\n",
      "Epoch 204/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 12.5008 - val_loss: 20.8244\n",
      "Epoch 205/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 12.4507 - val_loss: 20.9126\n",
      "Epoch 206/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.3862 - val_loss: 20.8695\n",
      "Epoch 207/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.3235 - val_loss: 20.8433\n",
      "Epoch 208/500\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 12.2706 - val_loss: 20.7720\n",
      "Epoch 209/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 12.2043 - val_loss: 20.8889\n",
      "Epoch 210/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.1509 - val_loss: 20.8633\n",
      "Epoch 211/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.1002 - val_loss: 20.8614\n",
      "Epoch 212/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.0465 - val_loss: 20.9879\n",
      "Epoch 213/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.0048 - val_loss: 20.8205\n",
      "Epoch 214/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.9624 - val_loss: 20.8625\n",
      "Epoch 215/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 11.8841 - val_loss: 20.8845\n",
      "Epoch 216/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 11.8275 - val_loss: 20.8891\n",
      "Epoch 217/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.7822 - val_loss: 20.7869\n",
      "Epoch 218/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.7252 - val_loss: 20.8567\n",
      "Epoch 219/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 11.6760 - val_loss: 20.7516\n",
      "Epoch 220/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 11.6353 - val_loss: 20.6736\n",
      "Epoch 221/500\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 11.5965 - val_loss: 20.5766\n",
      "Epoch 222/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.5563 - val_loss: 20.6103\n",
      "Epoch 223/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.4997 - val_loss: 20.6830\n",
      "Epoch 224/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.4594 - val_loss: 20.6407\n",
      "Epoch 225/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.4057 - val_loss: 20.6860\n",
      "Epoch 226/500\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 11.3930 - val_loss: 20.4745\n",
      "Epoch 227/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.3275 - val_loss: 20.5754\n",
      "Epoch 228/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 11.2778 - val_loss: 20.6105\n",
      "Epoch 229/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.2216 - val_loss: 20.5555\n",
      "Epoch 230/500\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 11.1933 - val_loss: 20.4650\n",
      "Epoch 231/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.1328 - val_loss: 20.5138\n",
      "Epoch 232/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.1094 - val_loss: 20.6541\n",
      "Epoch 233/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.0573 - val_loss: 20.5513\n",
      "Epoch 234/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.0219 - val_loss: 20.6083\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 11.0070 - val_loss: 20.5007\n",
      "Epoch 236/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.9464 - val_loss: 20.4841\n",
      "Epoch 237/500\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 10.9125 - val_loss: 20.3783\n",
      "Epoch 238/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 10.8692 - val_loss: 20.4442\n",
      "Epoch 239/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.8342 - val_loss: 20.5536\n",
      "Epoch 240/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.7935 - val_loss: 20.5225\n",
      "Epoch 241/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.7807 - val_loss: 20.4134\n",
      "Epoch 242/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 10.7225 - val_loss: 20.5664\n",
      "Epoch 243/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 10.6792 - val_loss: 20.5600\n",
      "Epoch 244/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 10.6586 - val_loss: 20.5454\n",
      "Epoch 245/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 10.6637 - val_loss: 20.4244\n",
      "Epoch 246/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.5910 - val_loss: 20.5055\n",
      "Epoch 247/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.5630 - val_loss: 20.6500\n",
      "Epoch 248/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.5115 - val_loss: 20.5945\n",
      "Epoch 249/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 10.4867 - val_loss: 20.4662\n",
      "Epoch 250/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.4529 - val_loss: 20.4286\n",
      "Epoch 251/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.4205 - val_loss: 20.4268\n",
      "Epoch 252/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.3820 - val_loss: 20.3921\n",
      "Epoch 253/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.3860 - val_loss: 20.5341\n",
      "Epoch 254/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.3171 - val_loss: 20.5016\n",
      "Epoch 255/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.2843 - val_loss: 20.5030\n",
      "Epoch 256/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.2724 - val_loss: 20.4129\n",
      "Epoch 257/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.2408 - val_loss: 20.5521\n",
      "Epoch 258/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.2016 - val_loss: 20.4944\n",
      "Epoch 259/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.1708 - val_loss: 20.4363\n",
      "Epoch 260/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 10.1418 - val_loss: 20.4966\n",
      "Epoch 261/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.1182 - val_loss: 20.4243\n",
      "Epoch 262/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.1016 - val_loss: 20.4142\n",
      "Epoch 263/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.0786 - val_loss: 20.4094\n",
      "Epoch 264/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.0709 - val_loss: 20.5986\n",
      "Epoch 265/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 10.0176 - val_loss: 20.6126\n",
      "Epoch 266/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.9778 - val_loss: 20.4537\n",
      "Epoch 267/500\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 9.9660 - val_loss: 20.3707\n",
      "Epoch 268/500\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 9.9486 - val_loss: 20.3116\n",
      "Epoch 269/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.9116 - val_loss: 20.3388\n",
      "Epoch 270/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.8823 - val_loss: 20.4774\n",
      "Epoch 271/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.8866 - val_loss: 20.6843\n",
      "Epoch 272/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.8473 - val_loss: 20.4677\n",
      "Epoch 273/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.8214 - val_loss: 20.5186\n",
      "Epoch 274/500\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 9.8341 - val_loss: 20.2866\n",
      "Epoch 275/500\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 9.7557 - val_loss: 20.6076\n",
      "Epoch 276/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.7455 - val_loss: 20.7046\n",
      "Epoch 277/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.7307 - val_loss: 20.6230\n",
      "Epoch 278/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6908 - val_loss: 20.7504\n",
      "Epoch 279/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6637 - val_loss: 20.6352\n",
      "Epoch 280/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6465 - val_loss: 20.4408\n",
      "Epoch 281/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6354 - val_loss: 20.4924\n",
      "Epoch 282/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.6068 - val_loss: 20.6519\n",
      "Epoch 283/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.5892 - val_loss: 20.4128\n",
      "Epoch 284/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.5809 - val_loss: 20.5558\n",
      "Epoch 285/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.5495 - val_loss: 20.3426\n",
      "Epoch 286/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.5276 - val_loss: 20.4230\n",
      "Epoch 287/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.5239 - val_loss: 20.5874\n",
      "Epoch 288/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.4897 - val_loss: 20.5374\n",
      "Epoch 289/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.4886 - val_loss: 20.3668\n",
      "Epoch 290/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.4467 - val_loss: 20.6185\n",
      "Epoch 291/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.4273 - val_loss: 20.6190\n",
      "Epoch 292/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.4167 - val_loss: 20.6116\n",
      "Epoch 293/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.3952 - val_loss: 20.6290\n",
      "Epoch 294/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.3754 - val_loss: 20.3529\n",
      "Epoch 295/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.3595 - val_loss: 20.4876\n",
      "Epoch 296/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.3384 - val_loss: 20.6730\n",
      "Epoch 297/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.3312 - val_loss: 20.3844\n",
      "Epoch 298/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.2889 - val_loss: 20.6626\n",
      "Epoch 299/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.2765 - val_loss: 20.6983\n",
      "Epoch 300/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.2596 - val_loss: 20.5697\n",
      "Epoch 301/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.2462 - val_loss: 20.4716\n",
      "Epoch 302/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.2280 - val_loss: 20.6953\n",
      "Epoch 303/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.2003 - val_loss: 20.5709\n",
      "Epoch 304/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.1810 - val_loss: 20.5043\n",
      "Epoch 305/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.1565 - val_loss: 20.5230\n",
      "Epoch 306/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.1382 - val_loss: 20.5494\n",
      "Epoch 307/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.1288 - val_loss: 20.6322\n",
      "Epoch 308/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.1021 - val_loss: 20.6134\n",
      "Epoch 309/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.0819 - val_loss: 20.5796\n",
      "Epoch 310/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.0792 - val_loss: 20.6412\n",
      "Epoch 311/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.0639 - val_loss: 20.3984\n",
      "Epoch 312/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.0302 - val_loss: 20.6372\n",
      "Epoch 313/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.0124 - val_loss: 20.7938\n",
      "Epoch 314/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 9.0006 - val_loss: 20.7546\n",
      "Epoch 315/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 8.9700 - val_loss: 20.5586\n",
      "Epoch 316/500\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 6.9376"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 183\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    294\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 295\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    297\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1401\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1400\u001b[0m   data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1401\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m         epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m         step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m         _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m       callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1248\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1248\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1249\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1250\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\n\u001b[0;32m   1253\u001b[0m     original_spe)\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:712\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m the read operation.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 712\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:691\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    689\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle()\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 691\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    695\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    696\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    697\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    698\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    699\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:681\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_and_set_handle\u001b[39m():\n\u001b[1;32m--> 681\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m   _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    684\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:478\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    x_train_norm, y_train, \n",
    "    epochs=500, \n",
    "    validation_data=(x_test_norm, y_test))\n",
    "\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "70gOV5Idme4w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 1\n",
      "units (Choice)\n",
      "{'default': 10, 'conditions': [], 'values': [10, 20, 30], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "zcF6Ogb_mtYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001D3D0FE27F0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 30\n",
      "Score: 15.598858833312988\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 10\n",
      "Score: 17.443344116210938\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of TF_Boston_Housing_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
